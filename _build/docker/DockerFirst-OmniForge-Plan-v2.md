# Docker-First OmniForge Bootstrap Plan (v2)

Target: Refactor OmniForge so **bootstrap workflows** run inside the `app` container by default, with Docker as the first “install” and the app’s `.env` becoming the long‑term source of truth. OmniForge is a **bootstrap-only tool**: once it has generated the app + Docker stack and `.env`, it is no longer needed and can be deleted by the developer.

The sequence below is ordered to stay incremental and recoverable.

---

## Repo Reality Check (current state)
- Entry: `omni.sh` → `bin/omni` (host). Menus/status work without Docker. `bin/omni` installs host-local `.tools` Node/pnpm and runs phases on the host.
- Validation: `lib/validation.sh` only checks `docker` binary and `docker info` when a phase declares deps; no compose helper.
- Compose/Dockerfiles: generated by `tech_stack/docker/*.sh`; secrets (DB password) and service creds are in `omni.config` or hardcoded defaults; compose uses inline env, not `env_file`.
- Env: tech_stack scripts write `.env.example` and sometimes `.env.local`; no central secrets helper.
- Additional services (redis/minio/meili/observability/traefik) are optional, driven by one-off scripts not wired to profiles or phases. All Docker artifacts/scripts live under `tech_stack/docker/`; examples live under `example-files/`. Docker assets should be generated into the project root, but their templates/installers live under `tech_stack/docker/`.

Each phase below calls out the delta from this baseline and the specific files to touch so we can execute one phase at a time and validate scope.

---

## Decisions from review (locked)
- Env file: single `.env` in repo root; used by host and container (`env_file: .env`). Treat `.env.local` as legacy; merge missing keys on first run without overwriting.
- Admin creds: seed `ADMIN_INITIAL_PASSWORD` into `.env` (admin user `admin`). Later password rotation is out of scope.
- No duplicate env files: only `.env`; no inline secret defaults in compose.
- Service start/order: bring up Docker first, then run the rest of the tech stack via a container-based installer that reads local config; add readiness waits before DB-dependent steps.
- Host helpers: provide a host Makefile or scripts under `/scripts/` with common app commands (e.g., `npm/pnpm dev`, etc.) for convenience; keep bootstrap work in container. Templates for these live under `tech_stack/docker/` (with examples in `example-files/`), and are generated to the host.
- Profiles: keep existing simple profiles; do not add new profile-based service fragmentation. Image/version pinning stays per-profile config and is applied by scripts.
- Secrets: generate strong random passwords during bootstrap; helper handles generation only (no rotation). Later “change all passwords” feature is separate.
- Logs: app/container logs stay in Docker; OmniForge logs stay where they are for install status.
- Docs: create a deployment checklist under `docs/omniforge-deployment/omni-deployment-checklist.md` (do not merge into OMNIFORGE.md). Developer-facing deployment notes live under `docs/omniforge-deployment/`.
- Docker assets: keep Dockerfiles/compose templates/scripts under `tech_stack/docker/`; examples under `example-files/`. `Dockerfile.dev` lives under `tech_stack/docker/` as a reusable template; generated/copy targets go to project root. One-time artifacts can use `.download-cache` if safe to delete after install.
- Fresh build assumption: plan assumes a fresh deployment (no legacy `.env.local`/`.tools`), but merge logic remains non-destructive if present.
- Docker-first default: For all new bootstraps, `DOCKER_EXEC_MODE=container` is the default and supported mode. Host mode is legacy/debug only.
- Menu-only safe commands: host-only allowed commands without Docker are `omni` (menu), `omni status`, `omni list/profiles/config` (read-only). No bootstrap/actions run without Docker.
- Post-bootstrap cleanup: Recommended to commit generated app artifacts and delete `_build/omniforge` once bootstrap is complete.
- APP_ENV_FILE: default is `<project root>/.env`. Projects using different layouts may override in `omni.settings.sh`.
- Mandatory services: the list of services to start (e.g., `APP_SERVICE_NAME`, Postgres when `ENABLE_DB=true`, others gated by flags) is defined in profile/config data, not hard-coded.
- Template staging: Dockerfile.dev, docker-compose.yml, .dockerignore are staged from `tech_stack/docker/` to project root prior to `docker compose up`; default behavior is to refresh/overwrite from templates unless explicitly configured otherwise.

---

## Phase 0 — Prep & Core Decisions

**Execution model**

- `omni.sh` can start on the **host** to:
  - Show menus
  - List profiles/phases
  - Show status/config
- Docker is **not** required just to view menus/info.
- When the user starts a **bootstrap / install** flow (e.g., “Option 1 – Bootstrap App” or `omni run` with a profile):
  - OmniForge performs a **Docker preflight** (CLI + daemon + compose).
  - Docker is treated as the **first software dependency**.
  - If Docker is healthy and `DOCKER_EXEC_MODE=container`, OmniForge:
    - Builds/starts the `app` container
    - Re-execs itself inside that container for all subsequent phase work.

**Bootstrap-only lifecycle**

- OmniForge’s job:
  - Read `omni.config` / `omni.settings.sh` (build-time template).
  - Run tech-stack scripts to generate:
    - Dockerfiles
    - `docker-compose` files
    - Application `.env` (with DB + admin credentials, etc.)
    - Code/config scaffolding
  - Leave behind a working Dockerized app.
- After a **successful bootstrap**:
  - The app’s `.env` and Docker files are the canonical configuration.
  - `_build/omniforge` is **no longer needed** and **may be deleted** by the developer.
  - The spec does **not** require or support ongoing lifecycle management via OmniForge.

**Config & secrets model**

- `omni.config` and `omni.settings.sh` are **build-time inputs only** (non-secret defaults, flags, and tech-stack options).
- During bootstrap:
  - OmniForge generates **random secrets** (DB password, admin initial password, etc.).
  - These are written into the **app’s `.env` file** (under the repo), which is then used by Docker/application at runtime.
- After bootstrap:
  - The app’s `.env` is the source of truth.
  - OmniForge config values are not required at runtime.

**Admin user**

- Initial admin account:
  - Username: `admin`
  - Password: randomly generated **12-character** password at bootstrap.
- OmniForge:
  - Writes this password into the app `.env` as `ADMIN_INITIAL_PASSWORD` (or equivalent).
  - Optionally logs a one-time message indicating where this value lives.
- Changing passwords / rotation is a **post-bootstrap checklist** feature (future enhancement), not part of this plan.

---

## Phase 1 — Docker Requirement & Re-Exec Shim

**Objective:** Require Docker for bootstrap, but only when the user actually starts an install/profile run. Provide a single helper set for compose/exec and support container re-exec.

**Changes**

1. **Config defaults (`omni.settings.sh`)**

   - Add the Docker flags, keeping host menu/status behavior unchanged.

   Add:

   ```bash
   DOCKER_REQUIRED="${DOCKER_REQUIRED:-true}"
   DOCKER_EXEC_MODE="${DOCKER_EXEC_MODE:-container}"  # "container" or "host"
   DOCKER_COMPOSE_FILE="${DOCKER_COMPOSE_FILE:-docker-compose.yml}"
   APP_SERVICE_NAME="${APP_SERVICE_NAME:-app}"
   ```

2. **Docker preflight (`lib/validation.sh`)**

   Add a `require_docker` function that:

   - Verifies `docker` CLI is installed.
   - Verifies Docker daemon is running (`docker info`).
   - Verifies `docker compose` (or `docker-compose`) is available.
   - Invoked only when a bootstrap/profile run is initiated (e.g., `omni run`, Option 1 menu), not for menu/status-only paths.
   - User-facing error UX: clear message if Docker is missing or daemon is down (“Docker is required to bootstrap. Install Docker and ensure the daemon is running, then rerun omni → Option 1.”)

3. **Docker helpers (`lib/docker.sh` or `lib/common.sh`)**

   Add:

   ```bash
   omni_docker_compose() {
     if command -v docker compose >/dev/null 2>&1; then
       docker compose -f "${DOCKER_COMPOSE_FILE}" "$@"
     else
       docker-compose -f "${DOCKER_COMPOSE_FILE}" "$@"
     fi
   }

   omni_docker_exec_app() {
     omni_docker_compose exec "${APP_SERVICE_NAME}" "$@"
   }

   omni_docker_run_app() {
     omni_docker_compose run --rm "${APP_SERVICE_NAME}" "$@"
   }
   ```

4. **Re-exec shim (`omni.sh`)**

   - `omni.sh` remains a **host entrypoint** capable of showing menus and status without Docker.
   - When a bootstrap/profile run is initiated:
     - Call `require_docker`.
     - Ensure core services are up (driven by config flags, e.g., `APP_SERVICE_NAME` plus mandatory infra like Postgres when `ENABLE_DB=true`; no hard-coded list).
     - If `DOCKER_EXEC_MODE=container` and `INSIDE_OMNI_DOCKER` is not set:
       - Re-exec OmniForge inside the app container:

       ```bash
       omni_docker_exec_app env INSIDE_OMNI_DOCKER=1 ./_build/omniforge/omni.sh "$@"
       exit $?
       ```
     - If `DOCKER_EXEC_MODE=host`, skip re-exec and run on host using host tools (legacy/debug only; not recommended).
     - `INSIDE_OMNI_DOCKER` is the flag all container-mode flows rely on; Phase 4 logic assumes it.

**Codex prompt:**

> Implement Phase 1 of `_build/docker/PLAN.md` (v2): add Docker gating, helpers, and re-exec logic so Docker is required **only when** starting a bootstrap/profile run, not just to display menus.

**Exit criteria / validation**
- `omni` menu works without Docker running.
- Starting `omni run` with `DOCKER_EXEC_MODE=container` brings up app+postgres, re-execs inside the container (e.g., `INSIDE_OMNI_DOCKER` visible in env), and otherwise behaves identically to current run flow.
- Templates (docker-compose.yml, Dockerfile.dev, .dockerignore) are staged from `tech_stack/docker/` to project root before `docker compose up`; preflight validates their presence. Log marker indicates container mode.

---

## Phase 2 — App Container & Compose Hardening

**Objective:** Ensure the `app` container can run OmniForge + pnpm and sits on the same network as runtime services.

**Changes**

1. **Dev Dockerfile (`tech_stack/docker/dockerfile-multistage.sh`)**

   Emit a `Dockerfile.dev` that:

   - Uses `node:${NODE_VERSION}-alpine` (or equivalent).
   - Installs pnpm globally.
   - Sets `WORKDIR /workspace`.
   - Includes tools needed by OmniForge scripts (bash, git, jq, curl, openssl).
   - Prod/multistage Dockerfile remains for production; not in scope for this phase.

2. **Compose (`tech_stack/docker/docker-compose-pg.sh`)**

   Ensure `docker-compose.yml` has:

   ```yaml
   services:
     app:
       build:
         context: .
         dockerfile: Dockerfile.dev
       volumes:
         - .:/workspace
       working_dir: /workspace
       networks:
         - ${APP_NAME}_network
       # env_file configured via app .env

     postgres:
       image: ${PG_IMAGE:-postgres:16}
       networks:
         - ${APP_NAME}_network

   networks:
     ${APP_NAME}_network:
       driver: bridge
   ```

   - Other core services (e.g., redis) share the same network if enabled.

3. **Service autostart**

   - Compose files are **generated**, but:
     - Scripts themselves do **not** automatically `up` services.
     - The re-exec shim in Phase 1 is responsible for bringing containers up at bootstrap time.
   - `app` runs with bind mount `.:/workspace` and can modify repo files (`package.json`, `.env`, `drizzle.config.ts`, etc.). `APP_NAME` must be safe for Docker naming; core services started are defined by flags (`ENABLE_DB`, `ENABLE_REDIS`, etc.), not hard-coded.

**Codex prompt:**

> Implement Phase 2 of `_build/docker/PLAN.md` (v2): harden `Dockerfile.dev` and `docker-compose.yml` so the `app` container can run OmniForge and share a network with Postgres and other services.

**Exit criteria / validation**
- `docker compose up -d app postgres` succeeds from the generated compose.
- `docker compose exec app pnpm -v` works and `WORKDIR` is `/workspace`.
- No scripts auto-start services; startup is driven by the Phase 1 shim.
- Host Makefile exists for common app commands (dev/build/test) without altering bootstrap flow.
- Dockerfile/compose templates remain under `tech_stack/docker/`; generated files land in project root; `.download-cache` is used only for disposable artifacts.
- `.dockerignore` template copied to project root; service/network naming normalized (e.g., `${APP_NAME}_network`). Host Makefile/scripts templates sourced from `tech_stack/docker/`.
- Core services to start are defined by flags (e.g., `ENABLE_DB`, `ENABLE_REDIS`), not hard-coded.

---

## Phase 3 — Secrets & Env Handling (App `.env` as Source of Truth)

**Objective:** Remove in-repo secrets from OmniForge config and centralize generated secrets into the app’s `.env`. No separate `omni.secrets.env` file.

**Changes**

1. **Clean up `omni.config`**

   - Remove any hardcoded secrets (e.g., `DB_PASSWORD` literal values).
   - Keep only **non-sensitive defaults**:
     - DB name, DB user, ports
     - Feature flags and profile options
     - Any other “template” values

2. **Secret generation helper (`lib/secrets.sh`)**

   Create a helper:

   ```bash
   APP_ENV_FILE="${APP_ENV_FILE:-.env}"  # or .env/.env.local depending on project convention

   generate_secret() {
     # 12-char alphanumeric by default for passwords
     openssl rand -base64 24 | tr -dc 'A-Za-z0-9' | head -c 12
   }

   ensure_env_var() {
     local key="$1"
     local value="$2"
     local file="${3:-${APP_ENV_FILE}}"

     touch "${file}"

     if grep -q "^${key}=" "${file}" 2>/dev/null; then
       return 0
     fi

     echo "${key}=${value}" >> "${file}"
     log "Set ${key} in ${file}"
   }

   ensure_random_secret() {
     local key="$1"
     local file="${2:-${APP_ENV_FILE}}"

     touch "${file}"

     if grep -q "^${key}=" "${file}" 2>/dev/null; then
       return 0
     fi

     local value
     value="$(generate_secret)"
     echo "${key}=${value}" >> "${file}"
     log "Generated secret ${key} in ${file}"
   }
   ```

3. **Apply to DB and admin user**

   - DB setup / Docker scripts:
     - Use `ensure_random_secret "DB_PASSWORD"` to generate a DB password into the app `.env`.
     - Ensure compose refers to `${DB_PASSWORD}` from that `.env`.
   - Admin user:
     - Use `ensure_random_secret "ADMIN_INITIAL_PASSWORD"`.
     - Document:
       - Admin username is `admin`.
       - Password is the generated `ADMIN_INITIAL_PASSWORD` value in `.env`.
       - It should be changed post-bootstrap.

4. **Compose wiring**

   Configure the `app` and `postgres` services to use the app `.env` file:

   ```yaml
   services:
     app:
       env_file:
         - .env

     postgres:
       env_file:
         - .env
   ```

**Codex prompt:**

> Implement Phase 3 of `_build/docker/PLAN.md` (v2): remove hardcoded secrets from `omni.config`, add helpers to generate secrets into the app’s `.env`, and wire Docker services to consume those env values.

**Exit criteria / validation**
- `omni.config` contains no secret literals.
- Running bootstrap produces `.env` with generated DB and admin secrets; compose references them via `env_file: .env`.
- Secrets are not added to `.env.example` beyond placeholders.
- `.env.local` (if present) is merged for missing keys only; existing values are not overwritten.
- Example env templates live under `example-files/`; runtime secrets are only written to `.env` (host and container).
- Secret generator uses strong length (e.g., 32+ chars); admin seeding is one-time/idempotent (only when no admin exists).
- If a key already exists in `.env`, it is not overridden (supports manual overrides and safe re-runs). Openssl dependency is explicit (installed in Dockerfile.dev and assumed available).
- Admin password surfacing: log username and the env var name (not the secret value) as the default; behavior can be overridden per profile/config if needed.
- Multi-environment secret handling (dev/stage/prod) is out of scope; assume single `.env` for local/dev.

---

## Phase 4 — Containerized Installs & Host Tool Isolation

**Objective:** Ensure OmniForge installs and code generation run **inside** the `app` container in Docker-first mode, and avoid host `.tools` usage in that path.

**Changes**

1. **Package installs (`tech_stack/_lib/pkg-install.sh`)**

   - When `INSIDE_OMNI_DOCKER=1`:
     - Assume `pnpm` and `node` are available in the container PATH.
     - Run `pnpm` commands directly (no host `.tools` logic).
   - Only use `.tools` or host `pnpm` if:
     - `DOCKER_EXEC_MODE=host`, or
     - Explicit legacy/host profile is being run.

2. **Local prereqs (`lib/prereqs-local.sh`)**

   - When `INSIDE_OMNI_DOCKER=1`:
     - Skip installing `.tools` Node/pnpm.
     - Assert that container has required binaries (via Dockerfile).

   - Document `.tools` as **legacy/host-only**:
     - Not used in Docker-first mode.
     - Existing `.tools` directories can be safely removed after migration.

3. **Bootstrap run path (`bin/omni`)**

   - In container mode, for a bootstrap/profile run:
     - `omni_docker_compose up -d app postgres` (and any unconditional core services).
     - Run all phases from within the container.
   - Host Node/pnpm is **not required** in Docker-first mode.

**Codex prompt:**

> Implement Phase 4 of `_build/docker/PLAN.md` (v2): route all installs through the `app` container in Docker mode and treat `.tools` as legacy host-only tooling.

**Exit criteria / validation**
- In container mode, `bin/omni` no longer installs `.tools`; installs/logs show container pnpm usage.
- Host-only mode remains functional when explicitly selected.
- After Docker `up`, remaining tech-stack steps run via a container-based installer/exec that reads local config; health waits precede DB-dependent steps.
- Re-exec occurs after templates are staged so the first container build succeeds; health-wait hook runs immediately after `up -d` before DB-dependent phases.
- Host mode is legacy only: `.tools` is used only there; it will not be extended and may be removed later. In container mode, if pnpm/node are missing, fail fast with a clear message (“Docker image missing pnpm/node; rebuild with Phase 2”). Log prefix (e.g., `[docker]`) when `INSIDE_OMNI_DOCKER=1` to distinguish context. Phase 4 assumes Phase 2 completed.

---

## Phase 5 — Script Contracts & Version Pinning

**Objective:** Clarify per-script inputs/outputs, enforce Docker-required phases, and pin Docker image versions per profile without new profile fragmentation.

**Changes**

1. **Phase metadata (`omni.phases.sh` / phase harness)**

   - Mark Docker as required for all phases that run installs (`docker_required=true`).

2. **Per-script contracts**

   - For core tech-stack scripts (Docker, DB, Auth, AI, Export, Env), document (comments/table):
     - **Inputs:** which `omni.*` variables they read.
     - **Outputs:** which files they generate or modify (`Dockerfile.dev`, `docker-compose.yml`, `.env` keys, `drizzle.config.ts`, etc.).
   - Example contract pattern:

     ```
     Script: tech_stack/docker/docker-compose-pg.sh
     Inputs: APP_NAME, DB_NAME, DB_USER, DB_PASSWORD, PG_IMAGE
     Outputs: docker-compose.yml (app + postgres services), .env (ensures DB_* keys exist)
     Runtime: Used by Docker compose only; OmniForge not required after bootstrap
     ```
   - Contracts required for core stack scripts only (Docker, DB, Auth, AI, Export, Env); smaller helpers can rely on comments.

3. **Version pinning per profile**

   - Keep image/version pins (Node, Postgres, etc.) in profile-aware config (omni*), and apply them in scripts without adding new profile flags. Log the resolved image tags during generation for traceability and ensure compose/Dockerfiles consume the same vars.

4. **Optional stack helpers**

   - Optionally expose simple stack commands (for bootstrap verification only):

     ```bash
     omni stack up     # omni_docker_compose up -d app postgres
     omni stack down   # omni_docker_compose down
     omni stack ps     # omni_docker_compose ps
     ```

**Codex prompt:**

> Implement Phase 5 of `_build/docker/PLAN.md` (v2): add per-script input/output docs, enforce Docker-required phases, and apply version pins per profile without introducing new profile fragmentation.

**Exit criteria / validation**
- Per-script inputs/outputs documented for core scripts (Docker, DB, Auth, AI, Export, Env).
- Docker-required phases enforced.
- Version pins applied from profile config consistently in compose and Dockerfiles.
- Resolved image tags are logged during generation for traceability.
- Profiles gate which scripts run, not how scripts behave; stack helpers (omni stack up/down/ps) are bootstrap-only conveniences and unsupported once OmniForge is removed.

---

## Phase 6 — Documentation & Migration

**Objective:** Document the new Docker-first bootstrap model and describe how to migrate from host-based OmniForge usage.

**Changes**

1. **Docs updates**

   Update `_build/omniforge/OMNIFORGE.md` and relevant docs (e.g., `docs/DEPENDENCY-ARCHITECTURE.md`) to include:

   - Explanation of the **Docker-first bootstrap model**:
     - `omni.sh` menu on host.
     - Docker preflight when starting bootstrap.
     - Re-exec into `app` container.
   - Description of **config flow**:
     - `omni.*` config → tech-stack scripts → app `.env` + Docker files.
     - App `.env` is the long-term source of truth.
   - Clarification that OmniForge is a **bootstrap-only tool**, not an app lifecycle manager.
   - Notes on `.tools` being legacy/host-only in Docker mode.

2. **Migration guidance**

   Add “Upgrading from Host-Based OmniForge”:

   - Steps:
     1. Ensure Docker is installed and functional.
     2. Run the new Docker-first bootstrap once to generate `Dockerfile.dev`, `docker-compose.yml`, and the app `.env`.
     3. Verify app runs with `docker compose up -d` and correct admin login.
     4. Stop relying on `.tools` for Node/pnpm in this project.
     5. Optionally delete `_build/omniforge` once satisfied with the generated stack.
   - Note:
     - Existing `.env.local` values can be retained or merged into the new app `.env` file.
     - Host-mode / legacy flows are no longer recommended and may be removed in future iterations.
    - Add `docs/omniforge-deployment/omni-deployment-checklist.md` as the deployment checklist (keep separate from OMNIFORGE.md and README).
    - Include note that OmniForge can be deleted after successful bootstrap and that app/container logs live in Docker while OmniForge logs remain for bootstrap status.
    - Add a brief CI blurb: run with `DOCKER_EXEC_MODE=host` (skip re-exec) or `docker compose up -d app postgres` + `docker compose exec app ./_build/omniforge/omni.sh --run`; note required services for tests.
    - Update ignored-files guidance (e.g., `_build/omniforge/logs/*`, temp state, legacy `.tools` if present).
    - Clarify re-run behavior: either detect-and-exit with “Already bootstrapped” or enforce idempotent re-run; choose one path and implement consistently.

**Codex prompt:**

> Implement Phase 6 of `_build/docker/PLAN.md` (v2): refresh documentation to reflect Docker-first bootstrap, and add a migration note for projects coming from host-based OmniForge.

---

## Acceptance Criteria – “Docker-First OmniForge Bootstrap is Working”

From a fresh clone of the project with Docker installed and no prior OmniForge artifacts, the following must be true:

1. **Bootstrap entry & Docker preflight**

   - Running `omni` on the host:
     - Shows the OmniForge menu and allows profile selection **without** requiring Docker to be running.
   - When the user starts **Option 1 – Bootstrap / Install** (or equivalent profile-run):
     - OmniForge performs Docker preflight (CLI + daemon + compose).
     - If Docker is unavailable, a clear error is shown and no scripts are run.
     - If Docker is available, OmniForge builds/starts the `app` container and re-execs inside it when in container mode.
   (AC1: Phases 0–1)

2. **App container & phase execution**

   - During bootstrap:
     - The `app` image is built from `Dockerfile.dev`.
     - `docker compose up -d app postgres` succeeds.
   - All phase scripts that install packages or mutate project files:
     - Execute **inside the `app` container** (log marker like `INSIDE_OMNI_DOCKER=1`).
     - Do **not** depend on host Node/pnpm in Docker-first mode.
   (AC2: Phases 1–4)

3. **Config & env handoff**

   - After a successful bootstrap:
     - An app `.env` file exists which contains:
       - DB connection details (host, name, port, user, generated password).
       - Admin credentials:
         - Username: `admin`
         - Password: a random 12-character value stored in a variable like `ADMIN_INITIAL_PASSWORD`.
     - `omni.*` configs have been used as **inputs** only.
     - The app `.env` and Docker files are the canonical configuration going forward.
   (AC3: Phases 3–4)

4. **Runtime behavior without OmniForge**

   - With OmniForge idle or deleted:
     - Running `docker compose up -d` starts the app and its services.
     - The app is accessible at the documented URL/port.
     - Logging in as `admin` with the password from `.env` works.
   - No OmniForge commands are required to run the app after bootstrap.
   (AC4: Phases 2–4)

5. **Host footprint & tool isolation**

   - In Docker-first mode:
     - No new `.tools` Node/pnpm environment is created or required.
     - OmniForge does not require host Node/pnpm.
   - Any OmniForge logs and temp files are confined to `_build/omniforge` and related log dirs, which are safe to delete after bootstrap.
   (AC5: Phases 1–4)

6. **Repeatability (safe re-run behavior)**

   - Re-running the bootstrap command on the same project either:
     - Detects that the project is already bootstrapped and exits with a clear message, **and** instructs to delete/rebuild if a new bootstrap is desired (no automatic re-run/idempotent reapply).
   - Behavior is documented: no re-run; delete and rebuild to change config.
   (AC6: Phases 3–6; fixed to detect-and-exit.)
   - CI check: In CI, using only generated Dockerfile/compose/.env (without OmniForge present), a minimal `docker compose build` + `pnpm test` (or equivalent) succeeds. No host Node/pnpm requirement in Docker-first mode is a hard requirement. Host vs compose-exec path is documented.
